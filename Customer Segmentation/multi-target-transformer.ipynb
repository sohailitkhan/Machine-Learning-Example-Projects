{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 444819 entries, 0 to 444818\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   client_id                 444819 non-null  object        \n",
      " 1   order_id                  444819 non-null  object        \n",
      " 2   orderdate                 444819 non-null  datetime64[ns]\n",
      " 3   city_id                   444819 non-null  object        \n",
      " 4   distance                  444819 non-null  float64       \n",
      " 5   aandm                     444819 non-null  float64       \n",
      " 6   basketvalue               444819 non-null  float64       \n",
      " 7   chargedamount             444819 non-null  float64       \n",
      " 8   deliveryfee               444819 non-null  float64       \n",
      " 9   discountamount            444819 non-null  float64       \n",
      " 10  supliersupport            444819 non-null  float64       \n",
      " 11  rating                    444819 non-null  float64       \n",
      " 12  warehouse_id              444819 non-null  object        \n",
      " 13  prev_order_count          444819 non-null  int64         \n",
      " 14  delivery_time             444819 non-null  float64       \n",
      " 15  decision_time             444819 non-null  float64       \n",
      " 16  discount_rate             444819 non-null  float64       \n",
      " 17  regain_potential          444819 non-null  float64       \n",
      " 18  regain_amount_cumsum      444819 non-null  float64       \n",
      " 19  next_order_price          246606 non-null  float64       \n",
      " 20  days_to_next_order        246606 non-null  float64       \n",
      " 21  order_frequency           323008 non-null  float64       \n",
      " 22  hex_delivery_time         444819 non-null  float64       \n",
      " 23  hex_regain_pot            444819 non-null  float64       \n",
      " 24  hex_charged_amount_avg    444819 non-null  float64       \n",
      " 25  using_frequency           438745 non-null  float64       \n",
      " 26  total_piece               444819 non-null  int64         \n",
      " 27  mean_price                444819 non-null  float64       \n",
      " 28  mastercategory_mode       444819 non-null  object        \n",
      " 29  brand_mode                444819 non-null  object        \n",
      " 30  subcategory_mode          444819 non-null  object        \n",
      " 31  product_mode              444819 non-null  object        \n",
      " 32  promo_id                  444819 non-null  object        \n",
      " 33  responsibledepartment_id  444819 non-null  object        \n",
      " 34  promoobjective            444819 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(22), int64(2), object(10)\n",
      "memory usage: 118.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "# Veri setini yükleme\n",
    "df = pd.read_csv('train_transformer.csv')\n",
    "\n",
    "\n",
    "# Eksik değerleri doldurma veya silme\n",
    "# Örnek: 'rating' sütunu için eksik değerleri ortalama ile doldurma\n",
    "df['rating'].fillna(0, inplace=True)\n",
    "\n",
    "# Veri türlerinin düzeltilmesi\n",
    "# Örnek: 'orderdate' sütununu datetime türüne dönüştürme\n",
    "df['orderdate'] = pd.to_datetime(df['orderdate'])\n",
    "# Veri setine genel bakış\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>city_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>aandm</th>\n",
       "      <th>chargedamount</th>\n",
       "      <th>deliveryfee</th>\n",
       "      <th>discountamount</th>\n",
       "      <th>supliersupport</th>\n",
       "      <th>rating</th>\n",
       "      <th>...</th>\n",
       "      <th>product_mode</th>\n",
       "      <th>promo_id</th>\n",
       "      <th>responsibledepartment_id</th>\n",
       "      <th>promoobjective</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>days_since_last_order</th>\n",
       "      <th>basketvalue</th>\n",
       "      <th>days_to_next_order</th>\n",
       "      <th>next_order_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6538ff945bbb65f457ca697d</td>\n",
       "      <td>2020-06-30 09:46:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>6.4050</td>\n",
       "      <td>16.4394</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.4400</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6538ff945bbb65f457ca697d</td>\n",
       "      <td>2020-07-14 17:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>5.4699</td>\n",
       "      <td>4.8500</td>\n",
       "      <td>1.79</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0600</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6538ff945bbb65f457ca697e</td>\n",
       "      <td>2020-06-30 10:11:00</td>\n",
       "      <td>0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>9.9455</td>\n",
       "      <td>5.2100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.5200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>970</td>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.7300</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.5105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6538ff945bbb65f457ca697e</td>\n",
       "      <td>2020-07-23 15:21:00</td>\n",
       "      <td>0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>5.0219</td>\n",
       "      <td>5.5105</td>\n",
       "      <td>1.79</td>\n",
       "      <td>8.2596</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.9801</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.6601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6538ff945bbb65f457ca6981</td>\n",
       "      <td>2020-06-30 14:07:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>6.8144</td>\n",
       "      <td>9.7898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.1502</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>978</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.5003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  client_id           orderdate  city_id  distance   aandm  \\\n",
       "0  6538ff945bbb65f457ca697d 2020-06-30 09:46:00        0    1373.0  6.4050   \n",
       "1  6538ff945bbb65f457ca697d 2020-07-14 17:48:00        0    1373.0  5.4699   \n",
       "3  6538ff945bbb65f457ca697e 2020-06-30 10:11:00        0     820.0  9.9455   \n",
       "4  6538ff945bbb65f457ca697e 2020-07-23 15:21:00        0     820.0  5.0219   \n",
       "8  6538ff945bbb65f457ca6981 2020-06-30 14:07:00        2    1360.0  6.8144   \n",
       "\n",
       "   chargedamount  deliveryfee  discountamount  supliersupport  rating  ...  \\\n",
       "0        16.4394         0.00         10.0006          0.0000     0.0  ...   \n",
       "1         4.8500         1.79          8.0000          0.0000     0.0  ...   \n",
       "3         5.2100         0.00         15.5200          0.0000     0.0  ...   \n",
       "4         5.5105         1.79          8.2596          0.1465     0.0  ...   \n",
       "8         9.7898         0.00         10.1502          0.0000     0.0  ...   \n",
       "\n",
       "   product_mode  promo_id  responsibledepartment_id  promoobjective  day  \\\n",
       "0           332       611                         0             1.0   30   \n",
       "1           195       280                         0             2.0   14   \n",
       "3           970       832                         0             1.0   30   \n",
       "4           221       280                         0             2.0   23   \n",
       "8           978       611                         0             1.0   30   \n",
       "\n",
       "   dayofweek  days_since_last_order  basketvalue  days_to_next_order  \\\n",
       "0          1                    0.0      26.4400                15.0   \n",
       "1          1                   14.0      11.0600                33.0   \n",
       "3          1                    0.0      20.7300                24.0   \n",
       "4          3                   23.0      11.9801                 9.0   \n",
       "8          1                    0.0      19.9400                 1.0   \n",
       "\n",
       "   next_order_price  \n",
       "0            4.8500  \n",
       "1           16.1710  \n",
       "3            5.5105  \n",
       "4            5.6601  \n",
       "8           16.5003  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dynamic_scaling(df, column, apply_threshold, max_threshold):\n",
    "    filtered_rows = df[df[column] > apply_threshold]\n",
    "    max_value = filtered_rows[column].max()\n",
    "    df.loc[filtered_rows.index, column] = apply_threshold + ((filtered_rows[column] - apply_threshold) / (max_value - apply_threshold)) * (max_threshold - apply_threshold)\n",
    "    return df\n",
    "\n",
    "df = dynamic_scaling(df, 'next_order_price', 80, 100)\n",
    "df = dynamic_scaling(df, 'days_to_next_order', 120, 140)\n",
    "# Tarih ve zamanla ilgili özellikler\n",
    "df['day'] = df['orderdate'].dt.day\n",
    "df['dayofweek'] = df['orderdate'].dt.dayofweek\n",
    "\n",
    "# Son siparişten bu yana geçen gün sayısı\n",
    "df['days_since_last_order'] = df.groupby('client_id')['orderdate'].diff().dt.days.fillna(0)\n",
    "\n",
    "# Normalleştirme\n",
    "\n",
    "\n",
    "categorical_features = df.select_dtypes(include=['object']).drop(['client_id', 'order_id', ],axis=1).columns\n",
    "# Label Encoding\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    df[column] = label_encoders[column].fit_transform(df[column])\n",
    "\n",
    "\n",
    "last_orders = df[df.days_to_next_order.isnull()]\n",
    "df = df[~df.days_to_next_order.isnull()]\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# use inputer for using_frequency column to fill the missing values\n",
    "df['using_frequency'] = imputer.fit_transform(df[['using_frequency']])\n",
    "\n",
    "# days_to_next_order sütununu ve chargedamount sütununu son 2 sütun yapma\n",
    "df = df[['client_id', 'orderdate', 'city_id', 'distance', 'aandm', 'chargedamount', 'deliveryfee', 'discountamount', 'supliersupport',\n",
    "       'rating', 'warehouse_id', 'prev_order_count', 'delivery_time','decision_time', 'discount_rate', 'regain_potential',\n",
    "       'regain_amount_cumsum', 'order_frequency', 'hex_delivery_time', 'hex_regain_pot', 'hex_charged_amount_avg',\n",
    "       'using_frequency', 'total_piece', 'mean_price', 'mastercategory_mode', 'brand_mode', 'subcategory_mode', 'product_mode', 'promo_id',\n",
    "       'responsibledepartment_id', 'promoobjective', 'day', 'dayofweek','days_since_last_order', 'basketvalue', \n",
    "       'days_to_next_order', 'next_order_price']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 68761 clients\n",
      "Test set contains 7641 clients\n",
      "Training set shape: (2, 35)\n",
      "Test set shape: (3, 35)\n",
      "Training set shape: torch.Size([2, 33])\n",
      "Test set shape: torch.Size([3, 33])\n",
      "Training set shape: torch.Size([68761, 20, 33])\n",
      "Test set shape: torch.Size([7641, 20, 33])\n"
     ]
    }
   ],
   "source": [
    "# DataFrame'de 'client_id' sütunu üzerinden gruplama yapılır\n",
    "grouped = df.groupby('client_id')\n",
    "\n",
    "# Her bir müşteri için sipariş geçmişini bir liste olarak oluştur\n",
    "sequences = {client: group.drop(columns=['client_id', 'orderdate']).values for client, group in grouped}\n",
    "\n",
    "# Eğitim ve test setleri için müşteri ID'lerini ayırma\n",
    "client_ids = df['client_id'].unique()\n",
    "np.random.shuffle(client_ids)\n",
    "train_ids = client_ids[:int(len(client_ids) * 0.9)]\n",
    "test_ids = client_ids[int(len(client_ids) * 0.9):]\n",
    "print(f\"Training set contains {len(train_ids)} clients\")\n",
    "print(f\"Test set contains {len(test_ids)} clients\")\n",
    "\n",
    "# Eğitim ve test setleri için dizileri oluşturma\n",
    "train_sequences = [sequences[client_id] for client_id in train_ids if client_id in sequences]\n",
    "test_sequences = [sequences[client_id] for client_id in test_ids if client_id in sequences]\n",
    "print(f\"Training set shape: {train_sequences[0].shape}\")\n",
    "print(f\"Test set shape: {test_sequences[0].shape}\")\n",
    "\n",
    "# drop the last 2 columns from the sequences which are chargedamount and days_to_next_order\n",
    "train_seq_dropped = [np.delete(sequence, [-2,-1], axis=1) for sequence in train_sequences]\n",
    "test_seq_dropped = [np.delete(sequence, [-2,-1], axis=1) for sequence in test_sequences]\n",
    "\n",
    "# Her müşteri için sipariş dizilerini PyTorch tensörlerine dönüştürme\n",
    "train_tensors = [torch.tensor(sequence, dtype=torch.float32) for sequence in train_seq_dropped]\n",
    "test_tensors = [torch.tensor(sequence, dtype=torch.float32) for sequence in test_seq_dropped]\n",
    "print(f\"Training set shape: {train_tensors[0].shape}\")\n",
    "print(f\"Test set shape: {test_tensors[0].shape}\")\n",
    "\n",
    "# Padding işlemi\n",
    "train_padded = pad_sequence(train_tensors, batch_first=True, padding_value=0.0)\n",
    "test_padded = pad_sequence(test_tensors, batch_first=True, padding_value=0.0)\n",
    "\n",
    "# Eğer diziler maksimum uzunluktan daha uzunsa, kırpma işlemi\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "train_padded = train_padded[:, :MAX_SEQUENCE_LENGTH, :]\n",
    "test_padded = test_padded[:, :MAX_SEQUENCE_LENGTH, :]\n",
    "print(f\"Training set shape: {train_padded.shape}\")\n",
    "print(f\"Test set shape: {test_padded.shape}\")\n",
    "# Hedef değişkenler için tensörleri hazırlama ve düzleştirme\n",
    "def prepare_labels(sequences, default_value=[0, 0]):\n",
    "    labels = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) > 0:\n",
    "            labels.append(seq[-1, -2:])\n",
    "        else:\n",
    "            labels.append(default_value)\n",
    "    # Önce numpy array'e dönüştür, sonra tensöre\n",
    "    return torch.tensor(np.array(labels), dtype=torch.float32)\n",
    "\n",
    "# Eğitim ve test hedeflerini hazırlama\n",
    "train_labels_tensor = prepare_labels(train_sequences)\n",
    "test_labels_tensor = prepare_labels(test_sequences)\n",
    "\n",
    "# Eğitim ve test veri setlerini PyTorch TensorDataset olarak oluşturma\n",
    "train_dataset = TensorDataset(train_padded, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_padded, test_labels_tensor)\n",
    "\n",
    "# Veri yükleyicilerini oluşturma\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=20):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1)].unsqueeze(0)\n",
    "        return x\n",
    "    \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, shared_hidden_dim, specific_hidden_dim, num_heads, num_layers, output_size):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.input_embedding = nn.Linear(input_size, shared_hidden_dim)\n",
    "        self.pos_encoder = PositionalEncoding(shared_hidden_dim)\n",
    "\n",
    "        # Paylaşılan Transformer Katmanları\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=shared_hidden_dim, nhead=num_heads, dropout=0.1, activation='relu', batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        # Hedef Spesifik Katmanlar\n",
    "        self.specific_layers_days = nn.Sequential(\n",
    "            nn.Linear(shared_hidden_dim, specific_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(specific_hidden_dim, output_size)\n",
    "        )\n",
    "        self.specific_layers_amount = nn.Sequential(\n",
    "            nn.Linear(shared_hidden_dim, specific_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(specific_hidden_dim, output_size)\n",
    "        )\n",
    "\n",
    "        # Dikkat Mekanizması\n",
    "        self.attention = nn.MultiheadAttention(shared_hidden_dim, num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = (src == 0.0).all(dim=2)  # Tüm özellikler 0 ise, bu bir padding elemanıdır\n",
    "        \n",
    "        src = self.input_embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        # Transformer Encoder'a mask uygula\n",
    "        shared_output = self.transformer_encoder(src, src_key_padding_mask=mask)\n",
    "\n",
    "        # Dikkat Mekanizması ile Context Vektörünü Elde Etme\n",
    "        attention_output, _ = self.attention(shared_output, shared_output, shared_output, key_padding_mask=mask)\n",
    "        \n",
    "        # Context Vektörünü Sonraki Katmanlara Aktarma\n",
    "        output_days = self.specific_layers_days(attention_output[:, -1, :])\n",
    "        output_amount = self.specific_layers_amount(attention_output[:, -1, :])\n",
    "\n",
    "        return output_days, output_amount\n",
    "\n",
    "\n",
    "    def get_specific_parameters_days(self):\n",
    "        return list(self.specific_layers_days.parameters())\n",
    "\n",
    "    def get_specific_parameters_amount(self):\n",
    "        return list(self.specific_layers_amount.parameters())\n",
    "\n",
    "class TransformerTrainer:\n",
    "    def __init__(self, model, train_loader, test_loader, learning_rate=1e-4):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion_days = nn.MSELoss()\n",
    "        self.criterion_amount = nn.MSELoss()\n",
    "        self.optimizer_shared = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "        self.optimizer_days = optim.Adam(model.get_specific_parameters_days(), lr=learning_rate)\n",
    "        self.optimizer_amount = optim.Adam(model.get_specific_parameters_amount(), lr=learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer_shared, 'min', min_lr=1e-7)\n",
    "\n",
    "    def train(self, epochs):\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        patience = 6\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            # Gradient Clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n",
    "            total_loss_days = 0\n",
    "            total_loss_amount = 0\n",
    "            for data, targets in self.train_loader:\n",
    "                self.optimizer_shared.zero_grad()\n",
    "                self.optimizer_days.zero_grad()\n",
    "                self.optimizer_amount.zero_grad()\n",
    "\n",
    "                output_days, output_amount = self.model(data)\n",
    "                \n",
    "                # Model çıktılarını sıkıştır\n",
    "                output_days = output_days.squeeze()\n",
    "                output_amount = output_amount.squeeze()\n",
    "                \n",
    "                loss_days = self.criterion_days(output_days, targets[:, 0])\n",
    "                loss_days.backward(retain_graph=True)\n",
    "                \n",
    "                loss_amount = self.criterion_amount(output_amount, targets[:, 1])\n",
    "                loss_amount.backward(retain_graph=True)\n",
    "                \n",
    "                total_loss = loss_days + loss_amount\n",
    "                total_loss.backward()\n",
    "                \n",
    "                self.optimizer_shared.step()\n",
    "                self.optimizer_amount.step()\n",
    "                self.optimizer_days.step()\n",
    "                \n",
    "                \n",
    "                total_loss_days += loss_days.item()\n",
    "                total_loss_amount += loss_amount.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Days Loss : {total_loss_days/len(self.train_loader):.6f}, Amount Loss : {total_loss_amount/len(self.train_loader):.6f}\")\n",
    "            # Modeli değerlendirme\n",
    "            val_loss_days, val_loss_amount, val_mse_days, val_mse_amount, val_mae_days, val_mae_amount, val_r2_days, val_r2_amount = self.evaluate()\n",
    "            eval_loss = val_loss_days + val_loss_amount\n",
    "            eval_loss /= len(self.test_loader)\n",
    "            self.scheduler.step(eval_loss)\n",
    "            if eval_loss < best_val_loss:\n",
    "                best_val_loss = eval_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "                \n",
    "            print(f\"Epoch {epoch+1} Evaluation - Days Loss: {val_loss_days/len(self.test_loader):.4f}, Amount Loss: {val_loss_amount/len(self.test_loader):.4f}, \"\n",
    "                f\"\\nDays MSE: {val_mse_days:.4f}, Amount MSE: {val_mse_amount:.4f}, \"\n",
    "                f\"\\nDays MAE: {val_mae_days:.4f}, Amount MAE: {val_mae_amount:.4f}, \"\n",
    "                f\"\\nDays R2: {val_r2_days:.4f}, Amount R2: {val_r2_amount:.4f}\")\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        total_loss_days = 0\n",
    "        total_loss_amount = 0\n",
    "        predictions_days = []\n",
    "        predictions_amount = []\n",
    "        actuals_days = []\n",
    "        actuals_amount = []\n",
    "        with torch.no_grad():\n",
    "            for data, targets in self.test_loader:\n",
    "                output_days, output_amount = self.model(data)\n",
    "                # Model çıktılarını sıkıştır\n",
    "                output_days = output_days.squeeze()\n",
    "                output_amount = output_amount.squeeze()\n",
    "                # Kayıpları topla\n",
    "                total_loss_days += self.criterion_days(output_days, targets[:, 0]).item()\n",
    "                total_loss_amount += self.criterion_amount(output_amount, targets[:, 1]).item()\n",
    "\n",
    "                # Tahminleri ve gerçek değerleri kaydet\n",
    "                predictions_days.extend(output_days.cpu().numpy())\n",
    "                predictions_amount.extend(output_amount.cpu().numpy())\n",
    "                actuals_days.extend(targets[:, 0].cpu().numpy())\n",
    "                actuals_amount.extend(targets[:, 1].cpu().numpy())\n",
    "\n",
    "        # Metriklerin hesaplanması\n",
    "        mse_days = mean_squared_error(actuals_days, predictions_days)\n",
    "        mse_amount = mean_squared_error(actuals_amount, predictions_amount)\n",
    "        mae_days = mean_absolute_error(actuals_days, predictions_days)\n",
    "        mae_amount = mean_absolute_error(actuals_amount, predictions_amount)\n",
    "        r2_days = r2_score(actuals_days, predictions_days)\n",
    "        r2_amount = r2_score(actuals_amount, predictions_amount)\n",
    "\n",
    "        return total_loss_days, total_loss_amount, mse_days, mse_amount, mae_days, mae_amount, r2_days, r2_amount\n",
    "\n",
    "input_size = train_padded.shape[2]  # Girdi boyutu\n",
    "shared_hidden_dim = 256  # Paylaşılan katmanlar için gizli boyut\n",
    "specific_hidden_dim = 128  # Hedef spesifik katmanlar için gizli boyut\n",
    "num_heads = 8  # Dikkat başlıkları sayısı\n",
    "num_layers = 4  # Transformer katman sayısı\n",
    "output_size = 1  # Her bir hedef için çıktı boyutu\n",
    "\n",
    "# Model örneği oluşturma\n",
    "model = CustomTransformerModel(input_size, shared_hidden_dim, specific_hidden_dim, num_heads, num_layers, output_size)\n",
    "\n",
    "# Eğitim sürecini yönetecek sınıfın oluşturulması\n",
    "trainer = TransformerTrainer(model, train_loader, test_loader)\n",
    "# Modelin eğitimi\n",
    "trainer.train(epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# Modelin eğitilmiş parametrelerini kaydetme\n",
    "torch.save(model.state_dict(), 'transformer_model_OPparam.pth')\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "#modeli kaydetme\n",
    "torch.save(model, 'transformer_model_OP.pth')\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelin degerlendirilmesi ve analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions_dataframe(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions_days = []\n",
    "    predictions_amount = []\n",
    "    actuals_days = []\n",
    "    actuals_amount = []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            output_days, output_amount = model(data)\n",
    "            predictions_days.extend(output_days.cpu().numpy().flatten())\n",
    "            predictions_amount.extend(output_amount.cpu().numpy().flatten())\n",
    "            actuals_days.extend(targets[:, 0].cpu().numpy())\n",
    "            actuals_amount.extend(targets[:, 1].cpu().numpy())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Actual Days to Next Order': actuals_days,\n",
    "        'Predicted Days to Next Order': predictions_days,\n",
    "        'Actual Charged Amount': actuals_amount,\n",
    "        'Predicted Charged Amount': predictions_amount\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Model ve test_loader örneklerini kullanarak DataFrame oluştur\n",
    "predictions_df = create_predictions_dataframe(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_vs_actuals(df, title, actual_col, predicted_col):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df[actual_col], df[predicted_col], alpha=0.6)\n",
    "    plt.title(f'{title}: Predictions vs Actuals')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.plot([df[actual_col].min(), df[actual_col].max()], [df[actual_col].min(), df[actual_col].max()], 'k--')  # İdeal çizgi\n",
    "    plt.show()\n",
    "\n",
    "# 'Days to Next Order' için tahminlerin ve gerçek değerlerin saçılım grafiği\n",
    "plot_predictions_vs_actuals(predictions_df, 'Days to Next Order', 'Actual Days to Next Order', 'Predicted Days to Next Order')\n",
    "\n",
    "# 'Charged Amount' için tahminlerin ve gerçek değerlerin saçılım grafiği\n",
    "plot_predictions_vs_actuals(predictions_df, 'Charged Amount', 'Actual Charged Amount', 'Predicted Charged Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_distribution(df, title, actual_col, predicted_col):\n",
    "    errors = df[predicted_col] - df[actual_col]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=50, alpha=0.7)\n",
    "    plt.title(f'{title}: Error Distribution')\n",
    "    plt.xlabel('Prediction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# 'Days to Next Order' için hata dağılımı\n",
    "plot_error_distribution(predictions_df, 'Days to Next Order', 'Actual Days to Next Order', 'Predicted Days to Next Order')\n",
    "\n",
    "# 'Charged Amount' için hata dağılımı\n",
    "plot_error_distribution(predictions_df, 'Charged Amount', 'Actual Charged Amount', 'Predicted Charged Amount')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
